{"name":"request-rate-limiter","description":"Call HTTP APIs that have rate limits and allow request bursts","version":"1.0.2","homepage":"https://github.com/eventEmitter/request-rate-limiter","license":"MIT","repository":"https://github.com/eventEmitter/request-rate-limiter","engines":{"node":">=v4"},"dependencies":{"ee-class":"1.x","ee-types":"2.x","leaky-bucket":"2.x","ee-log":"1.x","request":"2.53.x","async-method":"0.x.x","ee-argv":"0.1.x"},"devDependencies":{"mocha":"3.x","ee-webservice":"0.3.x"},"optionalDependencies":{},"keywords":["http","rate-limit","request","leaky-bucket"],"scripts":{"test":"./node_modules/mocha/bin/mocha --reporter spec"},"gitHead":"aefa0c19e374a776f933b34f4154c42c2359b9c9","versions":[{"number":"0.2.0","date":"2015-02-17T20:54:23.646Z"},{"number":"0.2.1","date":"2015-02-18T17:25:26.099Z"},{"number":"0.3.0","date":"2015-09-15T18:03:23.198Z"},{"number":"0.3.1","date":"2015-09-15T18:05:39.995Z"},{"number":"1.0.0","date":"2016-09-12T17:09:59.658Z"},{"number":"1.0.1","date":"2016-10-07T16:28:35.273Z"},{"number":"1.0.2","date":"2017-06-19T11:46:21.253Z"}],"readme":"# request-rate-limiter\n\nCall HTTP APIs that have rate limits and allow request bursts. This module depends on a leaky-bucket for doing the rate limit. Backs off when a HTTP 429 «Too Many Requests» is encountered.\n\nThis module uses [sematic versioning](http://semver.org/)\n\n## installation\n\n    npm i request-rate-limiter\n\n## build status\n\n[![Build Status](https://travis-ci.org/eventEmitter/request-rate-limiter.png?branch=master)](https://travis-ci.org/eventEmitter/request-rate-limiter)\n\n\n## API\n\nThe constructor accepts one argument. The argument can be a number (the rate limit) or an config object.\n\n\n    var RateLimiter = require('request-rate-limiter');\n\n\nCreate a rate limiter which can send 120 requests per minute.\n\n    var limiter = new RateLimiter(120);\n\nCreate a rate limiter which can send 60 requests per minute.\n\n    var limiter = new RateLimiter();\n\nCreate a rate limiter which can send 60 requests every 30 seconds.\n\n\n    var limiter = new RateLimiter({\n          rate: 60              // requests per interval,\n                                // defaults to 60\n        , interval: 30          // interval for the rate, x\n                                // requests per interval,\n                                // defaults to 60\n        , backoffCode: 429      // back off when this status is\n                                // returned, defaults to 429\n        , backoffTime: 10       // back off for n seconds,\n                                // defauts to rate/5\n        , maxWaitingTime: 300   // return errors for requests\n                                // that will have to wait for\n                                // n seconds or more. defaults\n                                // to 5 minutes\n    });\n\n\nIf requests are rejected because they cannot be executed in time, they will return out of order. This means if you enqueue 100 requests and only 70 can be sent in time, the 30 requests that cannot be executed will return with an error immediately, long before the other requests that are still enqueued.\n\n\n### Execute requests\n\nYou may either use the built in [request module by mikael](https://www.npmjs.com/package/request) or use your own request implementation.\n\n#### API Using the request module\n\nThe configuration passed to the «request» method gets passed directly to the [request module by mikael](https://www.npmjs.com/package/request). The response body, if present, is not returned as separate variable, it is instead available as the «body» property of the response object.\n\n\nExecute a request using callbacks\n\n    limiter.request({\n          url       : 'awesome.api/resource'\n        , method    : 'get'\n    }, function(err, response) {\n\n    });\n\n\nExecute a request using Promises\n\n\n    limiter.request({\n          url       : 'awesome.api/resource'\n        , method    : 'get'\n    }).then(function(response) {\n\n    }).catch(function(err) {\n\n    });\n\n\n\n#### API Using your own request implementation\n\n\nYou only have to pass a callback to the request method, it gets executed as soon as the request should be sent. Your callback gets two parameters passed to it, the first is the error object, the second is a function that can be called when the rate limiter should back off for a certain amount of time. If the backoff function is called the same callback is called again later when the remote api accepts requests again.\n\n\nExecute a request using callbacks\n\n    // queue request\n    limiter.request(function(err, backoff) {\n        if (err) {\n            // the err object is set if the limiter is overflowing or is not able to execute your request in time\n        else {\n\n            // its time to execute your request\n            request({url: 'http://joinbox.com/...'}, function(err, response, body) {\n                if (err) {\n                    // oh crap\n                }\n                else if (response.statusCode === 429) {\n\n                    // we have to back off. this callback will be called again as soon as the remote enpoint\n                    // should accept requests again. no need to queue your callback another time on the limiter.\n                    backoff();\n                }\n                else {\n                    // nice, your request looks good\n                }\n            });\n        }\n    });\n\n\n\nExecute a request using Promises\n\n    // queue request\n    limiter.request().then(function(backoff) {\n\n        // its time to execute your request\n        request({url: 'http://joinbox.com/...'}, function(err, response, body) {\n            if (err) callback(err);\n            else if (response.statusCode === 429) {\n\n                // we have to back off. this callback will be called again as soon as the remote enpoint\n                // should accept requests again. no need to queue your callback another time on the limiter.\n                backoff();\n            }\n            else callback(body);\n        });\n    }).catch(function(err) {\n\n         // the err object is set if the limiter is overflowing or is not able to execute your request in time\n    });\n","created":"2015-02-17T20:54:23.646Z","modified":"2017-06-19T11:46:21.253Z","lastPublisher":{"name":"ee","email":"michael@vanderweg.ch"},"owners":[{"name":"ee","email":"michael@vanderweg.ch"}],"other":{"_attachments":{},"_id":"request-rate-limiter","_nodeVersion":"8.1.1","_npmOperationalInternal":{"host":"s3://npm-registry-packages","tmp":"tmp/request-rate-limiter-1.0.2.tgz_1497872780216_0.8361623657401651"},"_npmUser":{"name":"ee","email":"michael@vanderweg.ch"},"_npmVersion":"5.0.3","_rev":"2-bad56a8d35110e99b5d41e6053328537","author":{"name":"Michael van der Weg","email":"michael@joinbox.com","url":"http://joinbox.com/"},"bugs":{"url":"https://github.com/eventEmitter/request-rate-limiter/issues"},"directories":{},"dist-tags":{"latest":"1.0.2"},"dist":{"integrity":"sha512-xFTz+yDvsjTr9ocF+mENkbpfKEH+udHQj9oU5PoELS3WujLQCrJDjwU9qNAWSm6RMzMe4D19ZBNnYVxQpv17RA==","shasum":"fd4653612ff7b843b8e613e7bf6c52fe742381f0","tarball":"https://registry.npmjs.org/request-rate-limiter/-/request-rate-limiter-1.0.2.tgz"},"maintainers":[{"name":"ee","email":"michael@vanderweg.ch"}],"readmeFilename":"README.md","time":{"modified":"2017-06-19T11:46:21.253Z","created":"2015-02-17T20:54:23.646Z","0.2.0":"2015-02-17T20:54:23.646Z","0.2.1":"2015-02-18T17:25:26.099Z","0.3.0":"2015-09-15T18:03:23.198Z","0.3.1":"2015-09-15T18:05:39.995Z","1.0.0":"2016-09-12T17:09:59.658Z","1.0.1":"2016-10-07T16:28:35.273Z","1.0.2":"2017-06-19T11:46:21.253Z"}}}