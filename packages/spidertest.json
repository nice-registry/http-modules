{"name":"spidertest","version":"0.0.10","description":"A test framework for verifying links and HTTP requests and their responses with automated test generation.","keywords":["spider","test automation"],"main":"lib/spiderTest.js","preferGlobal":"true","repository":"https://github.com/allanmboyd/spidertest","licenses":[{"type":"MIT","url":"http://www.opensource.org/licenses/mit-license.php"}],"bin":{"spidertest":"./bin/cli.js"},"scripts":{"start":"bin/cli.js","test":"./node_modules/jshint/bin/hint lib/spiderUtils.js lib/errors.js lib/Reporter.js lib/spider.js  lib/spiderOptions.js lib/spiderTest.js lib/suiteManager.js lib/reporters/ConsoleReporter.js lib/reporters/JUnitReporter.js lib/reporters/MultiFileJunitReporter.js test/testReporter.js test/testSpiderUtils.js test/testSpider.js test/testSuiteManager.js test/testSpiderTest.js bin/cli.js --config jshint-config.json && ./node_modules/nodeunit/bin/nodeunit test/testReporter.js test/testSpider.js test/testSuiteManager.js test/testSpiderTest.js test/testSpiderUtils.js"},"dependencies":{"cheerio":"0.7.0","exceptions":">= 0.1.1","formaterrors":">= 0.1.1","logly":">= 1.1.1","nconf":">= 0.5.1","optimist":">= 0.3.1","request":">= 2.2.9","routes":">= 0.1.0","underscore":">=1.3.3","xmldom":">= 0.1.1"},"devDependencies":{"async":">= 0.1.22","express":">= 2.5.8","jshint":"0.7.0","nodeunit":"0.7.4","should":">= 0.4.2"},"engine":{"node":">= 0.6.13"},"optionalDependencies":{},"engines":{"node":"*"},"_engineSupported":true,"_defaultsLoaded":true,"versions":[{"number":"0.0.1","date":"2012-05-16T15:23:52.001Z"},{"number":"0.0.3","date":"2012-05-28T12:53:48.335Z"},{"number":"0.0.4","date":"2012-05-28T13:05:04.660Z"},{"number":"0.0.5","date":"2012-05-29T13:54:42.036Z"},{"number":"0.0.6","date":"2012-05-30T09:53:02.122Z"},{"number":"0.0.8","date":"2012-06-12T15:52:29.666Z"},{"number":"0.0.9","date":"2012-06-13T14:18:20.770Z"},{"number":"0.0.10","date":"2012-06-15T09:38:35.214Z"}],"readme":"SpiderTest\n==========\n\nOverview\n--------\n\nSpiderTest is NodeJS module designed for lazy people - like me - who prefer to have a machine not only run a bunch of\nweb tests but also to kind of implement them too.\n\nFor example my website might have lots of different pages with links to other pages\nand resources like images, css, javascript - whatever. Assuming all of those pages and resources are accessible via\nURLs from some starting page (e.g. the home page) then I would like to make sure that all of those URLs work and that\nthey return the correct headers in the response. I might also want to ensure that common features on every html page like\nheaders, footers and menus are in the page and as expected. There might a subset of pages that should have the same\ncontent and I might want to check this is true. I might want to run some tests against CSS or Javascript content that\nis accessed also.\n\nIdeally I don't want to write the same tests multiple times for common features. Also, I don't really want to have\nto keep checking that all my tests cover all the links available especially since someone else could be modifying the\nsite. I want the machine to do these things for me.\n\nFinally, I want to have test reporting flexibility. I don't want my reporters to be coupled to the tests. I\nwould like to be able to write reporters that don't have to worry about running tests and I would like to\nprovide more than one if I want.\n\nSpiderTest aims to provide these features. It takes as input a start URL and a path to a folder containing test definitions\n(it's BDD by the way so tests can be nice and descriptive). If it gets a response from the start URL it\nlooks for any tests matching the URL and executes the ones that it finds. Then it looks at the response to find more\nlinks that it can request. If it finds any then it requests them, gets a response and executes any matching tests and\nso the cycle continues until there are no more URLs to test. Each matching test that it finds it associates with the\ncorresponding URL. By discovering URLs and pairing them up with tests SpiderTest could be said to be automating test\ngeneration. The test results for each URL tested are encapsulated within a test suite result set.\n\nSpiderTest reporters are event driven - or at least event driven in the way SAX parsers are event driven (I'm not saying\nthat reporters are SAX parsers btw just that they operate in the same way). When all the tests have been executed the\ntest results are iterated. Test results are structured as a hierarchy that comprises of test suites, topics and tests.\nEach visited URL that has one or more associated tests defines a test suite. Within a test suite (i.e. a matched URL)\nthere may be multiple topics and each topic may contain multiple individual tests.\n\nEach reporter implements an interface defined within __Reporter.js__ (this is documented below and in the code). The\nreporter callback methods are invoked as the tests are iterated providing the necessary information to generated test\nreports in a variety of formats at different levels of detail as required.\n\n\nTODO\n----\n\n- Provide a means to add request headers to be specified for tests\n- Expose more options\n- Better support JSON and XML responses (e.g. like finding URLs in these docs and using them)\n- Maybe support other kinds of HTTP request (other than GET)\n\n\nTest Definition\n---------------\n\nTests can use any third party assertion library (at least there are no deliberate restrictions). They\nare defined as an exported javascript object named __topics__. The topics object is composed of\na collection of topics. Each topic has an associated collection of tests as well as some\nadditional attributes that determine things like the URL patterns against which to apply\nthe topic tests. Each test within a topic is composed of a test name (which can be descriptive)\nand an associated function that performs the test. The test assert property is a function that receives a single\nparameter called the spiderPayload.\n\nHere is a very basic example:\n\n    var should = require(\"should\");\n    exports.topics = {\n        \"Common HTTP Tests\" : {\n            urlPattern: \"/\",\n            tests: {\n                \"HTTP responses should have a statusCode of 200\": {\n                    assert: function(spiderPayload) {\n                        should.equal(spiderPayload.response.statusCode, 200)\n                    }\n                }\n            }\n        }\n    }\n\nThe above test definition defines only a single topic with a single test - there can be\nmultiple of each within the topics object. The test asserts:\n\n_For any URL that includes a \"/\" run the associated tests. In this case the associated test\nis a single test that verifies that the HTTP status code of the response is equal to 200._\n\nThe name of the topic in the above example is __Common HTTP Tests___ and the name of the test\nis __HTTP responses should have a statusCode of 200__.\n\nThe __urlPattern__ attribute specifies a regular expression to use to match URLs. Each matched\nURL has the associated tests run against its response. A single URL may be matched multiple times\nin which case all associated tests are run.\n\n### Spider Payload ###\n\nThe Spider Payload is the object that is provided to each test assert function upon execution. It contains lots\nof data concerning the response of the associated HTTP request. A sample payload is provided in the examples folder\nas a full description is beyond the scope of this README. However, some of the more obviously useful properties\nare listed below:\n\n#### Response Headers ####\n\n    spiderPayload.response.headers.<headerName>\n\n\nProvide the values of HTTP response headers.\n\nExamples:\n    spiderPayload.response.headers['content-length']\n    spiderPayload.response.headers['accept-language']\n    spiderPayload.response.headers['content-type']\n\n#### Request URL ####\n\n    spiderPayload.url\n\nProvide the URL of the associated HTTP request.\n\nExamples:\n    spiderPayload.url.host\n    spiderPayload.url.href\n    spiderPayload.url.path\n\n#### Response Status ####\n\n    spiderPayload.response.statusCode\n\nProvide the HTTP response status code.\n\n#### Response Body ####\n\n    spiderPayload.response.body\n\nProvide the entire response document as a string.\n\nInstallation\n------------\n\n    npm install spidertest\n\nBy default spidertest installs globally.\n\n\nUsage\n-----\n\nSome examples:\n\n1. Spider test a website using default options and the tests defined in the examples/tests folder:\n\n    spidertest --testDir=/Users/aboyd/github/spiderTest/examples/tests --spiderStartUrl=http://subways.millionyearsold.com\n\n2. Same as above but this time specify a couple of reporters:\n\n\nReporters\n---------\n\nOut of the box SpiderTest comes with 3 reporters:\n\n- ConsoleReporter : output to the console in formatted text (this is the default reporter)\n- JUnitReporter : output to the console all test results as a single XML document in JUnit format\n- MultiFileJUnitReporter : output to the file system each test suite result set as an individual file\n\nAny of these (or all of them) can be specified as the reporters for a spidertest run. If no reporter is specified\nas an option then the ConsoleReporter is used.\n\nNew reporters can be created either by extended/editing any of the existing reporters or extending Reporter.js.\n\nReporters are specified using the __reporters__ option which should be a comma separated string of paths to the\nreporter modules to use. See spidertest --help for details.\n\nThe Reporter API is described below.\n\nReporter\n--------\n\nDefines an interface (and abstraction) that should be implemented by SpiderTest Reporter implementations to report\non the results of a SpiderTest test run.\n\nReporter instances are provided to a 'spidertest' invocation via command line or file based options. Each Reporter\ninstance will have its callback methods invoked when the reporting phase of SpiderTest kicks in subsequent to\ncompletion of all test executions.\n\nThe reporting phase of SpiderTest iterates over all tests result components in the same way a SAX Parser iterates\nover all the nodes of an XML document. Test result components consist of: testsuites, testsuite, topic, test,\ntestSuccess, testFailure, testError. These form a hierarchy with testsuites at the root.\n\nWhen a test result component is encountered during the results phase of SpiderTest one or more corresponding\ncallback methods within each provided reporter are invoked. These callback invocations provide the reporter with\nthe means to report on the test results.\n\nEach Reporter implementation should extend this Reporter class and override those methods that it needs to perform\nits required reporting function. There is no requirement to override every method.\n\n\n###Reporter.prototype.suitesStart = function ()###\n\nInvoked at the beginning of the reporting phase of SpiderTest. Indicates the start of the reporting phase.\n* * *\n\n\n###Reporter.prototype.suitesEnd = function(testCount, successCount, failedCount, errorCount, suitesTime)###\n\nThe final method to be invoked during the reporting phase of SpiderTest. Indicates the end of the reporting phase.\n\n####Parameters####\n\n* testCount *Number* the combined total number of tests executed\n* successCount *Number* the combined total number of tests that passed\n* failedCount *Number* the combined total number of tests that failed\n* errorCount *Number* the combined total number of errors that were generated by tests\n* suitesTime *Number* the combined total time in seconds that it took to execute tests. (Note that this does not include\nthe time that it takes to obtain responses from a web site - just the time for test execution against the spidered\nresponses.)\n* * *\n\n\n###Reporter.prototype.suiteStart = function(suiteName, suiteDescription, testCount, successCount, failedCount, errorCount, suiteTime)###\n\nInvoked when a new test suite is encountered.\n####Parameters####\n\n* suiteName *String* name of the suite. This is the URL that is associated the the tests within the suite.\n* suiteDescription *String* description of the suite. This is available if defined within the test definition.\n* testCount *Number* the number of tests in the suite\n* successCount *Number* the number of tests that passed in the suite\n* failedCount *Number* the number of tests that failed in the suite\n* errorCount *Number* the number of tests that generated an error (to be clear this refers to errors during\ntest execution as defined within the tests definitions and not to errors encountered spidering URLs)\n* suiteTime *Number* the time in seconds that it took to execute the tests in the test suite. (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered responses within the suite.)\n* * *\n\n\n###Reporter.prototype.suiteEnd = function()###\n\nInvoked at the end of a testsuite. Merely indicates that a transition to the next suite is about to occur having\ninvoked all the callbacks for all the tests within the current test suite.\n* * *\n\n\n###Reporter.prototype.topicStart = function(topicName, topicDescription, testCount, successCount, failedCount, errorCount, topicTime)###\n\nInvoked for each topic within a test suite. A topic allows several related tests to be grouped together.\n####Parameters####\n\n* topicName *String* the topic name as defined by the associated test definition\n* topicDescription *String* the description of the topic as defined by the associated test definition\n* testCount *Number* the number of tests in the topic\n* successCount *Number* the number of tests that passed in the topic\n* failedCount *Number* the number of tests that failed in the topic\n* errorCount *Number* the number of topic tests that generated an error (to be clear this refers to errors during\ntest execution as defined within the tests definitions and not to errors encountered spidering URLs)\n* topicTime *Number* the time in seconds that it took to execute the tests in the topic. (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered responses within the topic.)\n* * *\n\n\n###Reporter.prototype.topicEnd = function()###\n\nInvoked at the end of a topic. Merely indicates that a transition to the next topic is about to occur having\ninvoked all the callbacks for all the tests within the current topic.\n* * *\n\n\n###Reporter.prototype.testStart = function(testName, testTime, testFile)###\n\nInvoked for each test within a topic.\n####Parameters####\n\n* testName *String* the name of the test as defined by the associated test definition\n* testTime *Number* the time in seconds that it took to execute the test. (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered response.)\n* testFile *String* the name of the file containing the associated test definition from which the test was drawn\n* * *\n\n\n###Reporter.prototype.testEnd = function()###\n\nInvoked at the end of a test. Merely indicates that a transition to the next test is about to occur having\ninvoked all the callbacks associated with the current test.\n* * *\n\n\n###Reporter.prototype.testSuccess = function(testName, testTime, testFile)###\n\nInvoked for each successful test.\n####Parameters####\n\n* testName *String* the name of the test as defined by the associated test definition\n* testTime *Number* the time in seconds that it took to execute the test  (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered response.)\n* testFile *String* the name of the file containing the associated test definition from which the test was drawn\n* * *\n\n\n###Reporter.prototype.testFailure = function(testName, error, testTime, testFile)###\n\nInvoked for each failed test.\n####Parameters####\n\n* testName *String* the name of the test as defined by the associated test definition\n* testTime *Number* the time in seconds that it took to execute the test  (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered response.)\n* testFile *String* the name of the file containing the associated test definition from which the test was drawn\n* * *\n\n\n###Reporter.prototype.testError = function(testName, error, testTime, testFile)###\n\nInvoked for test that resulted in an error (to be clear this refers to errors during\ntest execution as defined within the tests definitions and not to errors encountered spidering URLs)\n####Parameters####\n\n* testName *String* the name of the test as defined by the associated test definition\n* testTime *Number* the time in seconds that it took to execute the test  (Note that this does not\ninclude the time that it takes to obtain responses from a web site - just the time for test execution against the\nspidered response.)\n* testFile *String* the name of the file containing the associated test definition from which the test was drawn\n* * *\n\n\n###module.exports = function ()###\n\nReporter implementations should inherit from the Reporter my requiring Reporter and invoking:\n     new Reporter();\n* * *\n\n\ncreateReporter\n--------------\n\n###exports.createReporter = function (options)###\n\nReporter implementations should implement this method to return a new instance of their Reporter.\n####Parameters####\n\n* options *String* to pass into the reporter. It is up to the reporter to determine what to do with these\noptions.\n\n####Returns####\n\n*Reporter* a new instance of Reporter that would be expected to override at least some of the Reporter\nprototype methods.\n* * *\n\n\n\n","created":"2012-05-16T15:23:50.810Z","modified":"2012-06-15T09:38:35.214Z","lastPublisher":{"name":"allanmboyd","email":"millionyearsold@gmail.com"},"owners":[{"name":"allanmboyd","email":"millionyearsold@gmail.com"}],"other":{"_attachments":{},"_id":"spidertest","_nodeVersion":"v0.6.13","_npmUser":{"name":"allanmboyd","email":"millionyearsold@gmail.com"},"_npmVersion":"1.1.9","_rev":"1-d6e0f50854f1adf2a7c7bb620664266d","author":{"name":"Allan Boyd","email":"millionyearsold@gmail.com"},"bugs":{"url":"http://github.com/allanmboyd/spidertest/issues"},"directories":{"lib":"./lib","example":"./examples"},"dist-tags":{"latest":"0.0.10"},"dist":{"shasum":"a5498abc21c3eadf9382f7763937868003169a12","tarball":"http://registry.npmjs.org/spidertest/-/spidertest-0.0.10.tgz"},"maintainers":[{"name":"allanmboyd","email":"millionyearsold@gmail.com"}],"time":{"modified":"2012-06-15T09:38:35.214Z","created":"2012-05-16T15:23:50.810Z","0.0.1":"2012-05-16T15:23:52.001Z","0.0.3":"2012-05-28T12:53:48.335Z","0.0.4":"2012-05-28T13:05:04.660Z","0.0.5":"2012-05-29T13:54:42.036Z","0.0.6":"2012-05-30T09:53:02.122Z","0.0.8":"2012-06-12T15:52:29.666Z","0.0.9":"2012-06-13T14:18:20.770Z","0.0.10":"2012-06-15T09:38:35.214Z"}}}